{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarinaOhm/NLP-using-N-grams/blob/main/NLP_using_N_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckrqxJkVJzPu"
      },
      "source": [
        "# Language modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jriJ3dZJ-c6",
        "outputId": "5e05189f-21c8-41cf-ced1-c67e56062c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX1bITPET_4Q",
        "outputId": "92a49f82-19ed-4a1f-e3cb-cbab6b1cd44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing packages needed for the project\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU9Ebp2CUaH3",
        "outputId": "748e4313-cd91-4747-bd96-0a5c36e9cc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The chosen text corpus contains: 192427 words\n",
            "The chosen text corpus contains: 7752 sentences\n"
          ]
        }
      ],
      "source": [
        "# Choosing the text 'Emma' by Jane Austin\n",
        "emma = gutenberg.words('austen-emma.txt')\n",
        "\n",
        "# Exploring the text corpus\n",
        "print('The chosen text corpus contains: ' + str(len(emma)) + ' words')\n",
        "\n",
        "emma_sentences=gutenberg.sents('austen-emma.txt')\n",
        "print('The chosen text corpus contains: ' + str(len(emma_sentences)) + ' sentences')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G48I6pnQarA"
      },
      "source": [
        "### Test corpus\n",
        "\n",
        "The following sentences will be used througout the assignment to test our uni-, bi-, and trigram models:\n",
        "1. never, did, she\n",
        "2. None, None, She\n",
        "3. None, She, did\n",
        "4. She, did, unknownword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jsLEFbJePZF"
      },
      "source": [
        "## Trigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkbrYp0dOl0q",
        "outputId": "09a3520f-b2de-49ab-e2e8-1aac6ff988f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count: 1\n",
            "Count: 460\n",
            "Count: 10\n",
            "Count: 0\n",
            "-----------------------------------\n",
            "Probability: 0.2\n",
            "Probability: 0.05933952528379773\n",
            "Probability: 0.021739130434782608\n",
            "Probability: 0.0\n"
          ]
        }
      ],
      "source": [
        "# First, we will build the trigram model\n",
        "\n",
        "# Initiating our dictionary used for storing our trigrams\n",
        "emma_model_trigram = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Looping throuch the sentences of the text\n",
        "for sentence in emma_sentences:\n",
        "  # Converting each sentence into trigrams. Setting padding to true in order to add indications in the beginning/end of sentences\n",
        "  for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "    # Counting one each time word 1 and word 2 are followed by word 3.\n",
        "    emma_model_trigram[(w1, w2)][w3] += 1\n",
        "\n",
        "# Testing cases\n",
        "print('Count: ' + str(emma_model_trigram[\"never\", \"did\"][\"she\"])) \n",
        "print('Count: ' + str(emma_model_trigram[None, None][\"She\"]))\n",
        "print('Count: ' + str(emma_model_trigram[None, \"She\"][\"did\"]))\n",
        "print('Count: ' + str(emma_model_trigram[\"She\", \"did\"][\"unknownword\"]))\n",
        "print('-----------------------------------')\n",
        "\n",
        "# Transforming the counts into probabilities\n",
        "for w1_w2 in emma_model_trigram:\n",
        "    total_count = float(sum(emma_model_trigram[w1_w2].values()))\n",
        "    for w3 in emma_model_trigram[w1_w2]:\n",
        "        emma_model_trigram[w1_w2][w3] /= total_count\n",
        "\n",
        "# Testing cases\n",
        "print('Probability: ' + str(emma_model_trigram[\"never\", \"did\"][\"she\"])) \n",
        "print('Probability: ' + str(emma_model_trigram[None, None][\"She\"]))\n",
        "print('Probability: ' + str(emma_model_trigram[None, \"She\"][\"did\"]))\n",
        "print('Probability: ' + str(emma_model_trigram[\"She\", \"did\"][\"unknownword\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIWIVRwFeSa1"
      },
      "source": [
        "## Bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiAUtcqFRNNY",
        "outputId": "3796603b-ae1d-47c9-d24d-709139790b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count: 6\n",
            "Count: 460\n",
            "Count: 15\n",
            "Count: 0\n",
            "-----------------------------------\n",
            "Probability: 0.01791044776119403\n",
            "Probability: 0.05933952528379773\n",
            "Probability: 0.026690391459074734\n",
            "Probability: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Building the bigram model similar to the trigram model, however this time we will only base it on one previous word\n",
        "\n",
        "emma_model_bigram = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "for sentence in emma_sentences:\n",
        "  # Insteas of w1, w2, w3 we now only use two words w1, w2 and the function bigrams() to convert sentences into bigrams\n",
        "  for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
        "    emma_model_bigram[w1][w2] += 1\n",
        "\n",
        "# Testing cases\n",
        "print('Count: ' + str(emma_model_bigram[\"did\"][\"she\"])) \n",
        "print('Count: ' + str(emma_model_bigram[None][\"She\"]))\n",
        "print('Count: ' + str(emma_model_bigram[\"She\"][\"did\"]))\n",
        "print('Count: ' + str(emma_model_bigram[\"did\"][\"unknownword\"]))\n",
        "print('-----------------------------------')\n",
        "\n",
        "# Transforming the counts into probabilities\n",
        "for w1 in emma_model_bigram:\n",
        "    total_count = float(sum(emma_model_bigram[w1].values()))\n",
        "    for w2 in emma_model_bigram[w1]:\n",
        "        emma_model_bigram[w1][w2] /= total_count\n",
        "\n",
        "\n",
        "# Testing cases\n",
        "print('Probability: ' + str(emma_model_bigram[\"did\"][\"she\"])) \n",
        "print('Probability: ' + str(emma_model_bigram[None][\"She\"]))\n",
        "print('Probability: ' + str(emma_model_bigram[\"She\"][\"did\"]))\n",
        "print('Probability: ' + str(emma_model_bigram[\"did\"][\"unknownword\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btoaEGnVfiCV"
      },
      "source": [
        "## Unigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgA3kdDCvekZ"
      },
      "outputs": [],
      "source": [
        "# Tokenizing the text to a dictionary stored with their frequency as value\n",
        "counts = Counter(gutenberg.words('austen-emma.txt'))\n",
        "\n",
        "# Counting the total number of words in the text\n",
        "total_count = len((gutenberg.words('austen-emma.txt')))\n",
        "\n",
        "def unigram_model(word):\n",
        "\n",
        "  # Calculating the probability as the number of time a given word occurs divided by the total number of words in the corpus\n",
        "  prob = counts[word] / float(total_count)\n",
        "\n",
        "  print('The word ' + word + ' appears ' + str(counts[word]) + ' times in the text. Meaning a probability of: ' + str(prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtJzQ_CwQe9",
        "outputId": "5a744471-1011-4d44-9f2e-b98b965825fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The word She appears 562 times in the text. Meaning a probability of: 0.002920588067163132\n",
            "The word unknownword appears 0 times in the text. Meaning a probability of: 0.0\n",
            "The word did appears 335 times in the text. Meaning a probability of: 0.0017409199332733972\n"
          ]
        }
      ],
      "source": [
        "unigram_model('She')\n",
        "unigram_model('unknownword')\n",
        "unigram_model('did')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-hBNRDXzwTX"
      },
      "source": [
        "## Interpolation model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create the interpolation model we turn the three models into functions. "
      ],
      "metadata": {
        "id": "G4OgCSeqNzPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLara4v8tu6q"
      },
      "outputs": [],
      "source": [
        "def unigram_model(unigram):\n",
        "  counts = Counter(gutenberg.words('austen-emma.txt'))\n",
        "  total_count = len((gutenberg.words('austen-emma.txt')))\n",
        "  prob_uni = counts[w1] / float(total_count)\n",
        "  return prob_uni\n",
        "\n",
        "\n",
        "def bigram_model(bigram):\n",
        "  w1=bigram[0]\n",
        "  w2=bigram[1]\n",
        "  emma_model_bigram = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  emma_model_bigram[w1][w2]\n",
        "  for sentence in emma_sentences:\n",
        "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
        "      emma_model_bigram[w1][w2] += 1\n",
        "  for w1 in emma_model_bigram:\n",
        "      total_count = float(sum(emma_model_bigram[w1].values()))\n",
        "      for w2 in emma_model_bigram[w1]:\n",
        "        if total_count != 0:\n",
        "          emma_model_bigram[w1][w2] /= total_count\n",
        "      return emma_model_bigram[w1][w2]\n",
        "\n",
        "def trigram_model(trigram):\n",
        "  [w1,w2]=[trigram[0],trigram[1]]\n",
        "  w3=trigram[2]\n",
        "  emma_model_trigram = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  for sentence in emma_sentences:\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "      emma_model_trigram[(w1, w2)][w3] += 1\n",
        "  for w1,w2 in emma_model_trigram:\n",
        "      total_count = float(sum(emma_model_trigram[w1,w2].values()))\n",
        "      for w3 in emma_model_trigram[w1,w2]:\n",
        "        if total_count != 0:\n",
        "          emma_model_trigram[w1,w2][w3] /= total_count\n",
        "      return emma_model_trigram[w1,w2][w3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interpolation model will draw upon the three models created above. \n",
        "\n",
        "The input must be a trigram, thus a list of length three. \n",
        "\n",
        "Additionally, the user must assign the lambda values."
      ],
      "metadata": {
        "id": "LBEaYzAvN8gh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkwSNpGWS4we"
      },
      "outputs": [],
      "source": [
        "def interpolation(trigram, lambda1, lambda2,lambda3):\n",
        "\n",
        "  assert len(trigram)==3;\n",
        "\n",
        "  unigram_input=trigram[2]\n",
        "  bigram_input=[trigram[1],trigram[2]]\n",
        "  trigram_input=[trigram[0],trigram[1],trigram[2]]\n",
        "  \n",
        "  prob=(lambda1 * unigram_model(unigram_input)) + (lambda2 * bigram_model(bigram_input))+(lambda3 * trigram_model(trigram_input))\n",
        "  \n",
        "  print(prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OWQyFbYzDo9",
        "outputId": "ee7d0d2f-3e6d-4fbc-ac05-38937bc7f98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0010397567902647156\n"
          ]
        }
      ],
      "source": [
        "# Testing the interpolation model\n",
        "interpolation_input=['never','did','she']\n",
        "interpolation(interpolation_input, lambda1=1/3,lambda2=1/3,lambda3=1/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KBPUwcaiUY"
      },
      "source": [
        "## Different Lambda values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaj6_pByRphO"
      },
      "outputs": [],
      "source": [
        "# Different lambda values for maximizing probability\n",
        "\n",
        "lambdas=[(0.2,0.4,0.4),(0.4,0.3,0.3),(0.2,0.3,0.5), (0.1,0.2,0.7)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0ZQ_aIE1i9e",
        "outputId": "ca238fed-0008-409d-a8f4-0f7d1b9b81a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interpolation model using lambdas: 0.2, 0.4, 0.4\n",
            "0.0012466687931336148\n",
            "-----------------------------------------------------\n",
            "Interpolation model using lambdas: 0.4, 0.3, 0.3\n",
            "0.0009363007888302659\n",
            "-----------------------------------------------------\n",
            "Interpolation model using lambdas: 0.2, 0.3, 0.5\n",
            "0.0009610612272478733\n",
            "-----------------------------------------------------\n",
            "Interpolation model using lambdas: 0.1, 0.2, 0.7\n",
            "0.0006878338805709354\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Looping though each tuple in the lambdas list. \n",
        "\n",
        "for i in lambdas:\n",
        "  x=i[0] \n",
        "  y=i[1]\n",
        "  z=i[2]\n",
        "  print('Interpolation model using lambdas: ' + str(x) + ', ' + str(y) + ', ' + str(z))\n",
        "\n",
        "  # Inserting the lambda values in the interpolation() function\n",
        "  interpolation(interpolation_input, lambda1=x, lambda2=y,lambda3=z)\n",
        "  \n",
        "  # Moving on to the next tuple\n",
        "  lambdas=+1 \n",
        "  \n",
        "  print('-----------------------------------------------------')\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we find that the lambdas 0.2, 0.4 and 0.4 brings the highest probability for the given test sentence"
      ],
      "metadata": {
        "id": "edwNpmuEOq8V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOMtHku1axYV"
      },
      "source": [
        "## Random sentences\n",
        "\n",
        "In the following we will generate some random text using trigrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_sent():\n",
        "\n",
        "  text = [None,None]\n",
        "  \n",
        "  # Variable used to break the while loop when turning True\n",
        "  end_sentence = False\n",
        "  \n",
        "  while not end_sentence:\n",
        "      rand_num = random.random()\n",
        "      acc = .0\n",
        "      \n",
        "      # For each iteration a random number generated from the random() function will be used as a benchmark for whether the word gets appended\n",
        "      for word in emma_model_trigram[tuple(text[-2:])].keys():\n",
        "          acc += emma_model_trigram[tuple(text[-2:])][word]\n",
        "          if acc >= rand_num:\n",
        "              text.append(word)\n",
        "              break\n",
        "          else:\n",
        "            continue\n",
        "      if text[-2:] == [None, None]:\n",
        "          end_sentence = True\n",
        "\n",
        "  print('The random sentence generated from our trigram model is: \\n >> ', ' '.join([t for t in text if t]))"
      ],
      "metadata": {
        "id": "H6SekPFZjhIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_random_sent()\n",
        "print('\\n')\n",
        "generate_random_sent()\n",
        "print('\\n')\n",
        "generate_random_sent()\n",
        "print('\\n')\n",
        "generate_random_sent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVL_ssVNjnc2",
        "outputId": "d0c5a438-0ecc-40b4-c8b4-8cde2a28f175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The random sentence generated from our trigram model is: \n",
            " >>  He had his influence , such very good opinion of herself , in reply , Mr . Weston , if not towards William Larkins is such a worshipping wife , \" must have been so thoroughly from the saddle of mutton for dinner , as my brother , whose prospects were closing , while their two fathers were engaged .-- It was known that you were here ?\n",
            "\n",
            "\n",
            "The random sentence generated from our trigram model is: \n",
            " >>  \" You should not have believed it !\n",
            "\n",
            "\n",
            "The random sentence generated from our trigram model is: \n",
            " >>  He had met her before , passed suspiciously through Emma ' s difference -- which one should expect to marry well , had been alone !-- Such a change !\n",
            "\n",
            "\n",
            "The random sentence generated from our trigram model is: \n",
            " >>  \" Yes , I do not want ; consequence I do not commit yourself .\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above sentences we find that the model in general creates random sentences that makes sense such as not having several nouns, pronouns or verbs right after each other. \n",
        "A weakness is the use of signs in the text like ; and ! and \" that sometimes appear quite random througout the sentences. "
      ],
      "metadata": {
        "id": "8YlwQhPMkVp5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQtFrrg1bLk"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu7JBF61umfZ"
      },
      "source": [
        "### Question 2 is answered using pen and paper (see word document). "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP using N-grams",
      "provenance": [],
      "authorship_tag": "ABX9TyMtOFZ4Ex2GjabMoP4s7iUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}